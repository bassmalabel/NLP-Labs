{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6cf0eee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/bishi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/bishi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/bishi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Necessary import \n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e9d1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "55338ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text': newsgroups_data.data, 'target_id': newsgroups_data.target})\n",
    "df['target_name'] = df['target_id'].apply(lambda x: newsgroups_data.target_names[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8c78a386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18846, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the number of samples \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4134f7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rec.sport.hockey', 'comp.sys.ibm.pc.hardware',\n",
       "       'talk.politics.mideast', 'comp.sys.mac.hardware',\n",
       "       'sci.electronics', 'talk.religion.misc', 'sci.crypt', 'sci.med',\n",
       "       'alt.atheism', 'rec.motorcycles', 'rec.autos', 'comp.windows.x',\n",
       "       'comp.graphics', 'sci.space', 'talk.politics.guns', 'misc.forsale',\n",
       "       'rec.sport.baseball', 'talk.politics.misc',\n",
       "       'comp.os.ms-windows.misc', 'soc.religion.christian'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the 20 categories names\n",
    "df['target_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce94c185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rec.sport.hockey', 'comp.sys.ibm.pc.hardware',\n",
       "       'talk.politics.mideast', 'comp.sys.mac.hardware',\n",
       "       'sci.electronics', 'talk.religion.misc', 'sci.crypt', 'sci.med',\n",
       "       'alt.atheism', 'rec.motorcycles', 'rec.autos', 'comp.windows.x',\n",
       "       'comp.graphics', 'sci.space', 'talk.politics.guns', 'misc.forsale',\n",
       "       'rec.sport.baseball', 'talk.politics.misc',\n",
       "       'comp.os.ms-windows.misc', 'soc.religion.christian'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "95c627aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_id</th>\n",
       "      <th>target_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target_id  \\\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...         10   \n",
       "1  My brother is in the market for a high-perform...          3   \n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...         17   \n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...          3   \n",
       "4  1)    I have an old Jasmine drive which I cann...          4   \n",
       "\n",
       "                target_name  \n",
       "0          rec.sport.hockey  \n",
       "1  comp.sys.ibm.pc.hardware  \n",
       "2     talk.politics.mideast  \n",
       "3  comp.sys.ibm.pc.hardware  \n",
       "4     comp.sys.mac.hardware  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the first 5 lines from the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd701924",
   "metadata": {},
   "source": [
    "First proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d54ae9",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f449ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.target_id\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.3, train_size=0.7, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb5e303",
   "metadata": {},
   "source": [
    "Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b07ee1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "01c9aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4bc90f",
   "metadata": {},
   "source": [
    "Removing punctuation, special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "82a440b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b52d80",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "78a58f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc8514",
   "metadata": {},
   "source": [
    "Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e635bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "df['tokens'] = df['tokens'].apply(lambda tokens: [t for t in tokens if t not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9231c6",
   "metadata": {},
   "source": [
    "Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "17b7f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['tokens'] = df['tokens'].apply(lambda tokens: [lemmatizer.lemmatize(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "42cbe20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['tokens'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51138c",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dea66b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text_clean'], df['target_id'], test_size=0.3, random_state=42, stratify=df['target_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c04b5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train) \n",
    "X_test = vectorizer.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3fe3c",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5f1492dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4730b9",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4ae66cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.69      0.37      0.48       240\n",
      "           comp.graphics       0.53      0.74      0.62       292\n",
      " comp.os.ms-windows.misc       0.94      0.22      0.36       296\n",
      "comp.sys.ibm.pc.hardware       0.62      0.73      0.67       295\n",
      "   comp.sys.mac.hardware       0.85      0.65      0.74       289\n",
      "          comp.windows.x       0.62      0.85      0.72       296\n",
      "            misc.forsale       0.88      0.65      0.75       293\n",
      "               rec.autos       0.82      0.71      0.76       297\n",
      "         rec.motorcycles       0.95      0.58      0.72       299\n",
      "      rec.sport.baseball       0.93      0.74      0.82       298\n",
      "        rec.sport.hockey       0.57      0.89      0.69       300\n",
      "               sci.crypt       0.71      0.77      0.74       297\n",
      "         sci.electronics       0.76      0.61      0.68       295\n",
      "                 sci.med       0.87      0.82      0.84       297\n",
      "               sci.space       0.82      0.75      0.78       296\n",
      "  soc.religion.christian       0.43      0.92      0.59       299\n",
      "      talk.politics.guns       0.64      0.71      0.67       273\n",
      "   talk.politics.mideast       0.64      0.80      0.71       282\n",
      "      talk.politics.misc       0.45      0.59      0.51       232\n",
      "      talk.religion.misc       0.91      0.05      0.10       188\n",
      "\n",
      "                accuracy                           0.67      5654\n",
      "               macro avg       0.73      0.66      0.65      5654\n",
      "            weighted avg       0.73      0.67      0.66      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=newsgroups_data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb24e1",
   "metadata": {},
   "source": [
    "We notice that with minimal text preprocessing, the model performed well on some categories and poorly on some others. \n",
    "We can inspect those categories more and try to do more preprocessing to clean the text and extract more insights from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c629a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_acc = ['alt.atheism','comp.graphics', 'comp.sys.ibm.pc.hardware', 'comp.windows.x', 'rec.autos', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc']\n",
    "high_acc = ['comp.os.ms-windows.misc', 'comp.sys.mac.hardware', 'misc.forsale', 'rec.motorcycles', 'rec.sport.baseball', 'talk.religion.misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6758464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keith\\n\\ni had a problem getting 256 colors i was stuck with 16 even though\\nthe flexstuff said i was at 1024256  i solved it by entering\\nthe advanced window on the flex program pannel and changing the\\ncolor palette  sorry for the vaugeness i hope it helps some\\n\\nbtw i have a gw200066v and 1m ati gup'\n",
      " 'and the lords servant must not quarrel instead he must be kind to everyone\\nable to teach not resentful those who oppose him he must gently instruct in\\nthe hope that god will grant them repentance leading them to a knowledge of the\\ntruth and that they will come to their senses and escape from the trap of the\\ndevil who has taken them captive to do his will \\niitimothy 22426\\n'\n",
      " '\\nso you think a 93 mustang cobra can match the performance of a new z28\\ninteresting belief \\n\\ncraig\\n\\nwho neither owns nor wants to own any gm or ford product'\n",
      " '\\n\\n\\n\\nthe fact that she was wearing a miniskirt with no underwear was\\npresented as evidence that she was a prostitute and the court\\napparently found this compelling\\n\\n\\nclayton does indeed know the difference  greg apparently doesnt\\n\\n\\n\\nbecause the judge found that there was some credible evidence that the\\nmarines were engaged in selfdefense  got it knucklehead\\n\\n\\n\\nbecause in part repeat after me the judge found that there was\\nsome credible evidence that the marines were engaged in selfdefense\\nhopefully one of these days you will understand\\n\\n\\nwith respect to credibility i would rate clayton cramer an order of\\nmagnitude higher than a the news media and b homosexuals\\n\\n\\nclayton is indeed consistent  and so are you'\n",
      " 'hi\\ni have a problem when compiled wcl 202 in sco odt 20\\n\\n\\n        cc c ox  i iusrinclude xt4getreslc\\nxt4getreslc\\nxt4getreslc47  error c2065 xtconstraintbit  undefined\\n error code 1\\n\\nalthough i follow the instructions in file readmebuild to build wcl in sco \\nplatform this problem didnt resolve\\n\\nso i have some questions related to this matter'\n",
      " '\\nin socreligionchristian you write\\n\\n\\nnote that the above type of prediction does not require a god to be made\\nan expert in a field can also predict things based on experience\\nbeware of predictions like the volcano will erupt tomorrow  dont\\nfollow the preacher because of such statements that come true\\n\\nnote also that if im describing a hypothetical death of a friend as\\na result of his passion for fast motorcycles i might say his mother\\npredicted he would die  of course his father may have said he ll\\nmake good money because of his hobby and depending upon the final\\noutcome of the situation i end up mentioning the one thats\\nrelevant  a reader down the road will get the impression that the\\nmother or father had predicted accurately the event when it was just\\na casual statement\\n\\nfinally on prophesies note that there are many prophesies that can be\\nfulfilled my people often to fool believers  if i say beware the\\nterminal will unexpectedly be shut off and then after 2 secs i turn\\nit off or have someone come out from another room and do it there was\\nno prediction  a similar situation arises with the establishment of\\nthe jewish state  while pressing for it prominent jews argued that it\\nwas predicted that theyd have a state again and that the time has\\ncome  ive read this somewhere but cant think of the source  if\\nyou can please let me know  in this case the establishment of the\\nstate does not really fulfill the  prophesy since the prophesy was used\\nin order to push for the establishment of the state\\n\\ndeciding what was truely a fulfillment of prophesy is very tricky\\n\\nleo\\n'\n",
      " '\\n\\n\\n\\n\\n\\ni think many reading this group would also benefit by knowing how\\ndeviant the view as ive articulated it above which may not be\\nthe true view of khomeini is from the basic principles of islam \\nso that the nonmuslim readers of this group will see how far from \\nthe simple basics of islam such views are on the face of them and \\nif they are not in contradiction with the basics of islam how \\nsubtle such issues are and how it seems sects exist in islam while \\nthey are explicitly proscribed by the quran\\n\\n\\n\\n\\nin my opinion considering any human being as having a substance\\nor metaphysical fundamentally different from that of any other human\\nbeing is a heretical notion and one proscribed by islam \\n\\n\\n\\n\\nabsolutely i would be interested in discussing this privately and\\ni am interested in hearing how one might try to make the concept of\\nerrorfree and sinless human beings philosophically consistent with\\nthe teachings of the quran however prima facie such attemptsa\\nare highly susceptible to degenerating into monkery explicitly\\nproscribed by the quran\\n\\n\\n\\nalaikum wassalam\\n'\n",
      " 'from thwangmentorccpurdueedu tommy hwang\\nsubject advise needed in buying automobile\\n\\n   i am in search of a dependable automobile to purchase  below\\n   are its requirements\\n   \\t5 v6 or above\\n\\n       most of the cars you mentioned are below smaller than v6 engine\\n\\n   tony\\n'\n",
      " '\\n\\ni have to agree with you the police may have carried it a bit too far\\nbut rodney king was no angel either and i dont think any guilty\\nverdicts should have been returned im sure you know why they handed\\ndown guilty verdicts on two of the officers its quite simple really\\nit was a compromise to avoid rioting in the places where minorities\\nthink its right to riot i hate to say this but i would have liked to\\nsee them riot with everyone prepared it would be open season if your\\nskin was even slightly brown\\n\\nhey my motto is you dont fuck with me or my stuff and you dont get\\nkilled its just that simple\\n\\ntony\\n\\n\\n anthony s pelliccio kd1nrae     yes you read it right the  \\n system  garlicsbscom           man who went from nocode    \\n thhhppptt to extra in     \\n flame retardent sysadmin        exactly one year            \\n\\n this is a calm sig '\n",
      " 'where can i get the winmarks benchmark to run on my pc\\nvia ftp would be best\\nroger']\n"
     ]
    }
   ],
   "source": [
    "df_low = df[df['target_name'].isin(low_acc)]\n",
    "print(df_low['text'].sample(10, random_state=42).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "150a9cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ni dont think ms has anything to brag about when it comes to following\\ndpmi but then consistency is the hobgoblin etc i suppose'\n",
      " '\\n\\n'\n",
      " 'hello\\n\\n\\twho can tell me   where can i find the pd or shareware   \\nwhich can capture windows 31s output of printer mananger\\n\\n\\ti want to capture the output of hp laser jet iii\\n\\n\\tthough the postscript can setup to print to filebut hp cant\\n\\n\\ti try doss redirect programbut they cant work in windows 31\\n\\n\\t\\tthankx for any help\\n\\n\\n internet address u7911093ccnctuedutw\\n\\n    english name erik wang\\n    chinese name wang jyhshyang'\n",
      " 'mitsbishi laptop mp 286l\\n\\n28612 1286 mhz switchable\\n2m ram installed\\nbacklit cga ext cga mga\\n20m 35hh hdd144m 35 fdd\\n2 com1 lpt ports\\ncomplete manual set\\nbuilt like a tank\\nexcellent cosmetic cond\\ndark gray\\nused very lightly\\n\\nproblems\\n1hdd stops working\\n2lcd sometimes doesnt work ext cagmga works'\n",
      " '\\n\\n\\n200 in glassboro new jersey  \\n'\n",
      " '\\nok here are some usefull applications and locations and other\\n\\non cica or mirrors in the desktop directory\\n\\nwrksft16 zip   39798 920915 wokshift graphical virtual desktop ver 16\\nemail author about version 20\\n\\ndesk240  zip  164690 921103 desktop tools for windows 3x\\nbackmenu 24  bigdesk  later version than backdesk\\n\\ntopdesk  zip   51051 920723 virtual windows for windows\\n\\n\\nfinder   zip  930329 a mac finder clone for windows\\nworks well with backmenu\\n\\n\\n\\nalso look out for superbar 20 due out soon  it allows button bars\\nto be added to almost any application'\n",
      " 'in maryland they were 25 each when i learned to ride 3 years ago now\\nits 125  for the beginner riders course and 60 for the experienced\\nriders course which admittedly takes only about half the time '\n",
      " '\\n\\n\\n\\nthe answer is  theyre stupid  seriously i think youre right\\non the money ive never understood the preoccupation with making\\nsure a rotation has lefthanded starters  the only time it makes\\nsense to me is when you have an unbalanced schedule and your main\\nrivals is loaded with lefthanded hitters  other than that i think\\nyoure completely right'\n",
      " 'hi there\\n\\ni wonder if anyone knows and can recommend me a good nubus display\\ncard for driving a 14 multisync nec 3d\\nthe nec 3d can do horizontal refresh from 155 khz to 38 khz and\\nvertical from 50 hz to 90 hz and can do max 1024x768 interlaced\\nthough i am looking for something more like 800x600 or 832x624\\nnoninterlaced\\nit would be very nice to find a card which can be programmed quite\\nfreely within these limits and is capable to display at least\\n8bitspixel preferably more\\n\\nis there anything on the market that comes even close\\n\\n\\nthanks\\n'\n",
      " 'im looking to but a sharp el5200 scientific calculator\\n\\nthe model is discontinued but if you know of any dealer which may have\\nthem around please reply\\n\\njason\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "df_high = df[df['target_name'].isin(high_acc)]\n",
    "print(df_high['text'].sample(10, random_state=42).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1b7d72b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 7277), ('would', 7048), ('x', 6130), ('people', 5066), ('1', 4911), ('dont', 4374), ('know', 4259), ('like', 4219), ('get', 4054), ('0', 3996), ('2', 3929), ('time', 3802), ('also', 3732), ('think', 3537), ('use', 3449), ('u', 3109), ('say', 2980), ('file', 2956), ('make', 2900), ('could', 2879)]\n"
     ]
    }
   ],
   "source": [
    "low_texts = ' '.join(df_low['text_clean'].values)\n",
    "low_words = Counter(low_texts.split())\n",
    "print(low_words.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aec6dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('maxaxaxaxaxaxaxaxaxaxaxaxaxaxax', 3307), ('one', 2296), ('1', 2104), ('would', 1957), ('get', 1576), ('like', 1541), ('2', 1540), ('dont', 1431), ('know', 1379), ('window', 1308), ('time', 1143), ('new', 1116), ('good', 1107), ('think', 1102), ('also', 1077), ('im', 1066), ('year', 1048), ('use', 1004), ('file', 987), ('problem', 986)]\n"
     ]
    }
   ],
   "source": [
    "high_texts = ' '.join(df_high['text_clean'].values)\n",
    "high_words = Counter(high_texts.split())\n",
    "print(high_words.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b3821",
   "metadata": {},
   "source": [
    "We notice that words that frequently appear in both categories are not very informative about the actual category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d496c1",
   "metadata": {},
   "source": [
    "We can do another analysis of the most frequent words in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "51b03310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the low_acc category: alt.atheism\n",
      " the most common words: [('one', 692), ('god', 692), ('would', 496), ('people', 495), ('dont', 435), ('say', 400), ('think', 374), ('atheist', 363), ('religion', 303), ('belief', 297), ('know', 297), ('make', 293), ('believe', 282), ('like', 273), ('argument', 273), ('thing', 272), ('time', 271), ('many', 268), ('even', 244), ('way', 241)]\n",
      "the low_acc category: comp.graphics\n",
      " the most common words: [('image', 1599), ('file', 1038), ('jpeg', 670), ('format', 627), ('program', 608), ('graphic', 592), ('also', 499), ('available', 454), ('system', 443), ('software', 443), ('data', 439), ('would', 438), ('use', 437), ('color', 416), ('one', 409), ('version', 393), ('get', 373), ('display', 358), ('like', 346), ('gif', 339)]\n",
      "the low_acc category: comp.sys.ibm.pc.hardware\n",
      " the most common words: [('drive', 978), ('card', 532), ('one', 437), ('system', 419), ('would', 384), ('disk', 381), ('scsi', 372), ('controller', 355), ('problem', 352), ('use', 347), ('get', 345), ('know', 328), ('work', 299), ('ide', 296), ('2', 296), ('like', 284), ('also', 258), ('im', 257), ('hard', 256), ('bus', 255)]\n",
      "the low_acc category: comp.windows.x\n",
      " the most common words: [('x', 5697), ('window', 1061), ('file', 1028), ('use', 751), ('program', 705), ('server', 626), ('get', 568), ('widget', 566), ('application', 514), ('entry', 474), ('one', 472), ('system', 448), ('version', 444), ('also', 428), ('set', 418), ('using', 413), ('available', 405), ('display', 397), ('motif', 391), ('would', 375)]\n",
      "the low_acc category: rec.autos\n",
      " the most common words: [('car', 1140), ('one', 365), ('would', 362), ('like', 324), ('get', 313), ('engine', 269), ('dont', 269), ('also', 262), ('know', 240), ('new', 227), ('good', 220), ('think', 211), ('time', 206), ('much', 202), ('problem', 197), ('year', 188), ('im', 173), ('well', 173), ('make', 164), ('may', 160)]\n",
      "the low_acc category: rec.sport.hockey\n",
      " the most common words: [('0', 3366), ('1', 2987), ('2', 2126), ('3', 1230), ('game', 1176), ('4', 1064), ('team', 845), ('5', 747), ('6', 633), ('7', 606), ('25', 551), ('hockey', 493), ('player', 475), ('play', 432), ('year', 417), ('10', 407), ('goal', 401), ('one', 392), ('would', 392), ('period', 386)]\n",
      "the low_acc category: sci.crypt\n",
      " the most common words: [('key', 1344), ('would', 787), ('chip', 723), ('one', 704), ('encryption', 678), ('government', 640), ('use', 621), ('system', 591), ('db', 549), ('people', 518), ('clipper', 507), ('u', 439), ('dont', 413), ('could', 405), ('get', 401), ('phone', 399), ('like', 396), ('security', 390), ('know', 388), ('message', 388)]\n",
      "the low_acc category: sci.electronics\n",
      " the most common words: [('one', 514), ('would', 450), ('use', 376), ('get', 283), ('like', 282), ('know', 267), ('dont', 265), ('circuit', 256), ('used', 253), ('wire', 235), ('power', 220), ('work', 214), ('also', 208), ('time', 203), ('need', 202), ('could', 202), ('anyone', 196), ('good', 190), ('ground', 182), ('may', 179)]\n",
      "the low_acc category: soc.religion.christian\n",
      " the most common words: [('god', 1907), ('one', 1102), ('would', 1038), ('christian', 791), ('people', 764), ('church', 723), ('jesus', 680), ('say', 605), ('know', 579), ('u', 559), ('think', 543), ('christ', 541), ('time', 507), ('also', 491), ('sin', 485), ('dont', 485), ('believe', 477), ('thing', 462), ('word', 458), ('like', 457)]\n",
      "the low_acc category: talk.politics.guns\n",
      " the most common words: [('gun', 992), ('would', 725), ('people', 601), ('one', 534), ('right', 443), ('dont', 407), ('weapon', 393), ('firearm', 378), ('law', 366), ('state', 344), ('get', 336), ('time', 330), ('like', 315), ('file', 315), ('government', 291), ('think', 289), ('fire', 289), ('fbi', 280), ('know', 272), ('well', 262)]\n",
      "the low_acc category: talk.politics.mideast\n",
      " the most common words: [('armenian', 1760), ('people', 1195), ('one', 1074), ('would', 803), ('said', 772), ('israel', 770), ('jew', 729), ('u', 697), ('turkish', 658), ('right', 563), ('muslim', 559), ('israeli', 558), ('say', 554), ('time', 554), ('arab', 553), ('know', 545), ('like', 511), ('dont', 491), ('government', 461), ('state', 460)]\n",
      "the low_acc category: talk.politics.misc\n",
      " the most common words: [('q', 933), ('people', 821), ('would', 798), ('president', 699), ('think', 660), ('mr', 609), ('dont', 596), ('one', 582), ('know', 518), ('stephanopoulos', 450), ('government', 442), ('u', 427), ('right', 425), ('well', 416), ('going', 412), ('state', 399), ('time', 397), ('make', 378), ('say', 372), ('like', 372)]\n",
      "the high acc category: comp.os.ms-windows.misc\n",
      " the most common words: [('maxaxaxaxaxaxaxaxaxaxaxaxaxaxax', 3307), ('window', 1154), ('file', 770), ('do', 381), ('use', 377), ('problem', 358), ('driver', 355), ('one', 329), ('get', 299), ('like', 294), ('program', 289), ('know', 279), ('would', 276), ('using', 260), ('system', 256), ('dont', 253), ('card', 240), ('work', 225), ('31', 224), ('run', 220)]\n",
      "the high acc category: comp.sys.mac.hardware\n",
      " the most common words: [('mac', 562), ('drive', 415), ('apple', 404), ('one', 395), ('problem', 382), ('would', 346), ('system', 343), ('get', 332), ('know', 287), ('use', 276), ('monitor', 260), ('like', 259), ('work', 252), ('card', 246), ('disk', 236), ('im', 221), ('anyone', 214), ('machine', 211), ('dont', 203), ('also', 198)]\n",
      "the high acc category: misc.forsale\n",
      " the most common words: [('1', 1194), ('2', 812), ('new', 450), ('sale', 406), ('3', 406), ('offer', 379), ('price', 318), ('email', 314), ('one', 313), ('drive', 305), ('please', 302), ('shipping', 282), ('4', 262), ('condition', 248), ('5', 244), ('system', 228), ('card', 226), ('good', 208), ('game', 207), ('10', 205)]\n",
      "the high acc category: rec.motorcycles\n",
      " the most common words: [('bike', 662), ('one', 373), ('like', 309), ('get', 300), ('would', 278), ('dont', 256), ('know', 211), ('ride', 208), ('im', 205), ('well', 202), ('dod', 201), ('time', 194), ('make', 179), ('good', 173), ('motorcycle', 173), ('go', 167), ('think', 166), ('back', 166), ('dog', 160), ('right', 156)]\n",
      "the high acc category: rec.sport.baseball\n",
      " the most common words: [('game', 689), ('year', 604), ('1', 485), ('0', 468), ('would', 465), ('team', 420), ('player', 375), ('one', 375), ('think', 338), ('2', 323), ('dont', 320), ('get', 314), ('run', 310), ('last', 307), ('3', 301), ('hit', 296), ('time', 290), ('good', 290), ('like', 263), ('well', 254)]\n",
      "the high acc category: talk.religion.misc\n",
      " the most common words: [('god', 687), ('one', 511), ('jesus', 406), ('would', 405), ('people', 405), ('christian', 358), ('say', 339), ('dont', 267), ('know', 263), ('bible', 256), ('think', 255), ('see', 241), ('u', 225), ('even', 225), ('also', 225), ('word', 219), ('like', 216), ('way', 213), ('thing', 211), ('time', 209)]\n"
     ]
    }
   ],
   "source": [
    "cats = ['alt.atheism','comp.graphics', 'comp.sys.ibm.pc.hardware', 'comp.windows.x', 'rec.autos', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc','comp.os.ms-windows.misc', 'comp.sys.mac.hardware', 'misc.forsale', 'rec.motorcycles', 'rec.sport.baseball', 'talk.religion.misc']\n",
    "\n",
    "for cat in cats: \n",
    "    df_ = df[df['target_name']== cat]\n",
    "    texts = ' '.join(df_['text_clean'].values)\n",
    "    words = Counter(texts.split())\n",
    "    if cat in low_acc:\n",
    "        acc = 'low_acc'\n",
    "    else: \n",
    "        acc = 'high acc'\n",
    "    print(f'the {acc} category: {cat}\\n the most common words: {words.most_common(20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a2f6c",
   "metadata": {},
   "source": [
    "Most of these categories have highly relevant keywords to the catogory's topics, which is a good sign, however there are some generic words that appear in every category and do not carry strong topical information, we can remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "703235dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ext = set(stopwords.words('english'))\n",
    "\n",
    "extra_stopwords = [\"one\", \"would\", \"people\", \"say\", \"get\", \"know\", \"like\", \"use\", \"think\", \"could\", \"also\", \"year\", \"make\", \"dont\", \"time\", \"good\", \"many\", \"way\"]\n",
    "stop_words_ext.update(extra_stopwords)\n",
    "\n",
    "df['text_clean'] = df['text_clean'].apply(lambda text: ' '.join([w for w in text.split() if w not in stop_words_ext]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b07f71",
   "metadata": {},
   "source": [
    "We can go the extra mile and do more specific analysis by calculating the ratio of verbs and nouns in each category, this way we can note if certain categories have noticeably higher noun or verb ratios. \n",
    "We can also use these as extra features, but it's not possible with Naive Bayes classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d81f6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=[\"parser\", \"ner\"])\n",
    "\n",
    "def nouns_ratio(text):\n",
    "    doc = nlp(text)\n",
    "    total = len(doc)\n",
    "    num_nv = sum(1 for token in doc if token.pos_ in ['VERB'])\n",
    "    return num_nv / total if total > 0 else 0\n",
    "def verbs_ratio(text):\n",
    "    doc = nlp(text)\n",
    "    total = len(doc)\n",
    "    num_nv = sum(1 for token in doc if token.pos_ in ['VERB'])\n",
    "    return num_nv / total if total > 0 else 0\n",
    "df['nouns_ratio'] = df['text_clean'].apply(nouns_ratio)\n",
    "df['verbs_ratio'] = df['text_clean'].apply(verbs_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bde65fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun ratios by category:\n",
      " target_name\n",
      "misc.forsale                0.136816\n",
      "comp.sys.mac.hardware       0.171935\n",
      "sci.electronics             0.172546\n",
      "rec.sport.hockey            0.174089\n",
      "comp.os.ms-windows.misc     0.174563\n",
      "rec.sport.baseball          0.174691\n",
      "comp.sys.ibm.pc.hardware    0.175830\n",
      "sci.space                   0.175959\n",
      "rec.autos                   0.178305\n",
      "comp.graphics               0.178542\n",
      "sci.crypt                   0.187456\n",
      "sci.med                     0.188866\n",
      "comp.windows.x              0.191285\n",
      "talk.politics.misc          0.192612\n",
      "rec.motorcycles             0.193686\n",
      "talk.politics.mideast       0.198095\n",
      "talk.religion.misc          0.202052\n",
      "talk.politics.guns          0.203956\n",
      "soc.religion.christian      0.207637\n",
      "alt.atheism                 0.207963\n",
      "Name: nouns_ratio, dtype: float64\n",
      "\n",
      "Verb ratios by category:\n",
      " target_name\n",
      "misc.forsale                0.136816\n",
      "comp.sys.mac.hardware       0.171935\n",
      "sci.electronics             0.172546\n",
      "rec.sport.hockey            0.174089\n",
      "comp.os.ms-windows.misc     0.174563\n",
      "rec.sport.baseball          0.174691\n",
      "comp.sys.ibm.pc.hardware    0.175830\n",
      "sci.space                   0.175959\n",
      "rec.autos                   0.178305\n",
      "comp.graphics               0.178542\n",
      "sci.crypt                   0.187456\n",
      "sci.med                     0.188866\n",
      "comp.windows.x              0.191285\n",
      "talk.politics.misc          0.192612\n",
      "rec.motorcycles             0.193686\n",
      "talk.politics.mideast       0.198095\n",
      "talk.religion.misc          0.202052\n",
      "talk.politics.guns          0.203956\n",
      "soc.religion.christian      0.207637\n",
      "alt.atheism                 0.207963\n",
      "Name: verbs_ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "noun_ratio_per_cat = df.groupby('target_name')['nouns_ratio'].mean().sort_values()\n",
    "verb_ratio_per_cat = df.groupby('target_name')['verbs_ratio'].mean().sort_values()\n",
    "\n",
    "print(\"Noun ratios by category:\\n\", noun_ratio_per_cat)\n",
    "print(\"\\nVerb ratios by category:\\n\", verb_ratio_per_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485aca7",
   "metadata": {},
   "source": [
    "We notice that these ratios are small, this means there are too many other words with different POS tags that are frequent in each category.\n",
    "We can try to keep only three POS tags : Noun, Verbs and Adjectives, because they are more linguistically rich features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d84117eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=[\"parser\", \"ner\"])\n",
    "def filter_pos(text, pos_to_keep=['NOUN', 'VERB', 'ADJ']):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.pos_ in pos_to_keep]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['text_pos_filtered'] = df['text_clean'].apply(lambda text: filter_pos(text, ['NOUN', 'VERB', 'ADJ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1da701f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text_clean'], df['target_id'], test_size=0.3, random_state=42, stratify=df['target_id'])\n",
    "\n",
    "vectorizer_count = CountVectorizer()\n",
    "X_train_count = vectorizer_count.fit_transform(X_train)\n",
    "X_test_count = vectorizer_count.transform(X_test)\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "697e98cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Results with pos filtering:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "        rec.sport.hockey       0.67      0.38      0.48       240\n",
      "comp.sys.ibm.pc.hardware       0.53      0.74      0.62       292\n",
      "   talk.politics.mideast       0.90      0.22      0.35       296\n",
      "   comp.sys.mac.hardware       0.62      0.73      0.67       295\n",
      "         sci.electronics       0.83      0.66      0.74       289\n",
      "      talk.religion.misc       0.61      0.85      0.71       296\n",
      "               sci.crypt       0.87      0.65      0.75       293\n",
      "                 sci.med       0.83      0.72      0.77       297\n",
      "             alt.atheism       0.95      0.60      0.73       299\n",
      "         rec.motorcycles       0.95      0.74      0.83       298\n",
      "               rec.autos       0.57      0.90      0.70       300\n",
      "          comp.windows.x       0.73      0.78      0.75       297\n",
      "           comp.graphics       0.77      0.62      0.69       295\n",
      "               sci.space       0.88      0.82      0.85       297\n",
      "      talk.politics.guns       0.83      0.76      0.79       296\n",
      "            misc.forsale       0.45      0.91      0.61       299\n",
      "      rec.sport.baseball       0.63      0.71      0.67       273\n",
      "      talk.politics.misc       0.63      0.81      0.71       282\n",
      " comp.os.ms-windows.misc       0.49      0.61      0.54       232\n",
      "  soc.religion.christian       0.80      0.06      0.12       188\n",
      "\n",
      "                accuracy                           0.68      5654\n",
      "               macro avg       0.73      0.66      0.65      5654\n",
      "            weighted avg       0.73      0.68      0.67      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using CountVectorizer features\n",
    "clf_count = MultinomialNB()\n",
    "clf_count.fit(X_train_count, y_train)\n",
    "y_pred_count = clf_count.predict(X_test_count)\n",
    "\n",
    "\n",
    "print(\"CountVectorizer Results with pos filtering:\")\n",
    "print(classification_report(y_test, y_pred_count, target_names=df['target_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "de39351f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer Results with pos filtering:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "        rec.sport.hockey       0.78      0.28      0.41       240\n",
      "comp.sys.ibm.pc.hardware       0.70      0.68      0.69       292\n",
      "   talk.politics.mideast       0.72      0.66      0.68       296\n",
      "   comp.sys.mac.hardware       0.63      0.77      0.69       295\n",
      "         sci.electronics       0.85      0.66      0.74       289\n",
      "      talk.religion.misc       0.81      0.85      0.83       296\n",
      "               sci.crypt       0.83      0.73      0.78       293\n",
      "                 sci.med       0.81      0.76      0.79       297\n",
      "             alt.atheism       0.89      0.70      0.78       299\n",
      "         rec.motorcycles       0.93      0.80      0.86       298\n",
      "               rec.autos       0.57      0.94      0.71       300\n",
      "          comp.windows.x       0.68      0.85      0.75       297\n",
      "           comp.graphics       0.80      0.71      0.75       295\n",
      "               sci.space       0.88      0.82      0.85       297\n",
      "      talk.politics.guns       0.82      0.79      0.80       296\n",
      "            misc.forsale       0.41      0.93      0.57       299\n",
      "      rec.sport.baseball       0.63      0.77      0.69       273\n",
      "      talk.politics.misc       0.77      0.81      0.79       282\n",
      " comp.os.ms-windows.misc       0.90      0.36      0.51       232\n",
      "  soc.religion.christian       1.00      0.01      0.02       188\n",
      "\n",
      "                accuracy                           0.71      5654\n",
      "               macro avg       0.77      0.69      0.69      5654\n",
      "            weighted avg       0.77      0.71      0.70      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using TfidfVectorizer features\n",
    "clf_tfidf = MultinomialNB()\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "print(\"TfidfVectorizer Results with pos filtering:\")\n",
    "print(classification_report(y_test, y_pred_tfidf, target_names=df['target_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5265f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text_pos_filtered'], df['target_id'], test_size=0.3, random_state=42, stratify=df['target_id'])\n",
    "\n",
    "vectorizer_count = CountVectorizer()\n",
    "X_train_count = vectorizer_count.fit_transform(X_train)\n",
    "X_test_count = vectorizer_count.transform(X_test)\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8c22f47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Results with pos filtering:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "        rec.sport.hockey       0.59      0.38      0.46       240\n",
      "comp.sys.ibm.pc.hardware       0.53      0.69      0.60       292\n",
      "   talk.politics.mideast       0.71      0.25      0.37       296\n",
      "   comp.sys.mac.hardware       0.57      0.63      0.60       295\n",
      "         sci.electronics       0.75      0.56      0.64       289\n",
      "      talk.religion.misc       0.54      0.83      0.65       296\n",
      "               sci.crypt       0.80      0.59      0.68       293\n",
      "                 sci.med       0.75      0.69      0.72       297\n",
      "             alt.atheism       0.88      0.52      0.65       299\n",
      "         rec.motorcycles       0.91      0.65      0.76       298\n",
      "               rec.autos       0.53      0.89      0.67       300\n",
      "          comp.windows.x       0.70      0.73      0.72       297\n",
      "           comp.graphics       0.72      0.59      0.65       295\n",
      "               sci.space       0.87      0.81      0.84       297\n",
      "      talk.politics.guns       0.78      0.73      0.76       296\n",
      "            misc.forsale       0.45      0.86      0.59       299\n",
      "      rec.sport.baseball       0.63      0.63      0.63       273\n",
      "      talk.politics.misc       0.54      0.78      0.64       282\n",
      " comp.os.ms-windows.misc       0.46      0.55      0.50       232\n",
      "  soc.religion.christian       0.62      0.05      0.10       188\n",
      "\n",
      "                accuracy                           0.63      5654\n",
      "               macro avg       0.67      0.62      0.61      5654\n",
      "            weighted avg       0.67      0.63      0.62      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using CountVectorizer features\n",
    "clf_count = MultinomialNB()\n",
    "clf_count.fit(X_train_count, y_train)\n",
    "y_pred_count = clf_count.predict(X_test_count)\n",
    "\n",
    "\n",
    "print(\"CountVectorizer Results with pos filtering:\")\n",
    "print(classification_report(y_test, y_pred_count, target_names=df['target_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107aaeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer Results:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "        rec.sport.hockey       0.73      0.23      0.34       240\n",
      "comp.sys.ibm.pc.hardware       0.70      0.68      0.69       292\n",
      "   talk.politics.mideast       0.67      0.54      0.60       296\n",
      "   comp.sys.mac.hardware       0.55      0.73      0.63       295\n",
      "         sci.electronics       0.81      0.56      0.66       289\n",
      "      talk.religion.misc       0.71      0.84      0.77       296\n",
      "               sci.crypt       0.77      0.71      0.74       293\n",
      "                 sci.med       0.78      0.72      0.75       297\n",
      "             alt.atheism       0.84      0.66      0.74       299\n",
      "         rec.motorcycles       0.89      0.71      0.79       298\n",
      "               rec.autos       0.52      0.91      0.66       300\n",
      "          comp.windows.x       0.70      0.79      0.74       297\n",
      "           comp.graphics       0.74      0.65      0.69       295\n",
      "               sci.space       0.87      0.78      0.82       297\n",
      "      talk.politics.guns       0.83      0.77      0.80       296\n",
      "            misc.forsale       0.38      0.92      0.54       299\n",
      "      rec.sport.baseball       0.65      0.71      0.68       273\n",
      "      talk.politics.misc       0.68      0.79      0.73       282\n",
      " comp.os.ms-windows.misc       0.87      0.34      0.49       232\n",
      "  soc.religion.christian       1.00      0.01      0.01       188\n",
      "\n",
      "                accuracy                           0.67      5654\n",
      "               macro avg       0.73      0.65      0.64      5654\n",
      "            weighted avg       0.73      0.67      0.66      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using TfidfVectorizer features\n",
    "clf_tfidf = MultinomialNB()\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "print(\"TfidfVectorizer Results with pos filtering:\")\n",
    "print(classification_report(y_test, y_pred_tfidf, target_names=df['target_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68242ade",
   "metadata": {},
   "source": [
    "After POS-based filtering and TF-IDF vectorization, model accuracy remained 67%. Certain categories (like sci.space) saw strong F1 improvements, while others (soc.religion.christian) dropped dramatically indicating their reliance on non-content words for context. \n",
    "However with the additional preprocessing without the pos filtering step the accuracy seems to increase to 71% using TFidf vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620ff13",
   "metadata": {},
   "source": [
    "So we're going to try use the POS filtering only to the categories that benefited from it, and apply other preprocessing to the other categories, and see if we can achieve better accuracy or is this pos filtering useless. \n",
    "\n",
    "And since the TFidf vectorization seems to perform better everytime we will proceeed with it for the rest of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e45ea653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories that benefit from POS filtering\n",
    "pos_filter_cats = [\n",
    "    'alt.atheism', 'sci.space', 'talk.religion.misc', 'sci.crypt', 'sci.med'\n",
    "]\n",
    "\n",
    "# All other categories use standard cleaning\n",
    "standard_cats = [cat for cat in df['target_name'].unique() if cat not in pos_filter_cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "28d6efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocess(row):\n",
    "    if row['target_name'] in pos_filter_cats:\n",
    "        doc = nlp(row['text_clean'])\n",
    "        tokens = [token.lemma_ for token in doc if token.pos_ in ['NOUN', 'VERB', 'ADJ']]\n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return row['text_clean']\n",
    "\n",
    "df['text_hybrid'] = df.apply(custom_preprocess, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0ab0eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text_hybrid'], df['target_id'], test_size=0.3, random_state=42, stratify=df['target_id']\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fb6ac437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer Results with pos filtering:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "        rec.sport.hockey       0.57      0.66      0.61       240\n",
      "comp.sys.ibm.pc.hardware       0.64      0.64      0.64       292\n",
      "   talk.politics.mideast       0.62      0.60      0.61       296\n",
      "   comp.sys.mac.hardware       0.60      0.68      0.64       295\n",
      "         sci.electronics       0.77      0.64      0.70       289\n",
      "      talk.religion.misc       0.73      0.82      0.78       296\n",
      "               sci.crypt       0.81      0.75      0.78       293\n",
      "                 sci.med       0.72      0.69      0.70       297\n",
      "             alt.atheism       0.76      0.69      0.72       299\n",
      "         rec.motorcycles       0.86      0.79      0.82       298\n",
      "               rec.autos       0.53      0.91      0.67       300\n",
      "          comp.windows.x       0.81      0.85      0.83       297\n",
      "           comp.graphics       0.73      0.65      0.69       295\n",
      "               sci.space       0.79      0.82      0.80       297\n",
      "      talk.politics.guns       0.83      0.80      0.82       296\n",
      "            misc.forsale       0.73      0.91      0.81       299\n",
      "      rec.sport.baseball       0.68      0.78      0.72       273\n",
      "      talk.politics.misc       0.85      0.77      0.81       282\n",
      " comp.os.ms-windows.misc       0.83      0.50      0.62       232\n",
      "  soc.religion.christian       0.77      0.13      0.22       188\n",
      "\n",
      "                accuracy                           0.72      5654\n",
      "               macro avg       0.73      0.70      0.70      5654\n",
      "            weighted avg       0.73      0.72      0.71      5654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using TfidfVectorizer features\n",
    "clf_tfidf = MultinomialNB()\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "print(\"TfidfVectorizer Results with pos filtering:\")\n",
    "print(classification_report(y_test, y_pred_tfidf, target_names=df['target_name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bbef58",
   "metadata": {},
   "source": [
    "No big improvement. but we'll keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "98c200bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8108702243784112\n",
      "Test Accuracy: 0.7175451008135834\n"
     ]
    }
   ],
   "source": [
    "train_pred = clf_tfidf.predict(X_train_tfidf)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "print(\"Training Accuracy:\", train_acc)\n",
    "test_acc = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc72a983",
   "metadata": {},
   "source": [
    "A 10% gap is relatively good knowing that we have 20 classes and high-cardinality text data. But it still indicates fitting to specific training data noise or details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9ba9f",
   "metadata": {},
   "source": [
    "Trying to increase the accuracy by reducing the vocabulary size (to reduce noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a3b03ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text_hybrid'], df['target_id'], test_size=0.3, random_state=42, stratify=df['target_id']\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,4), max_features=3000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6cce1914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7833535476046088\n",
      "Test Accuracy: 0.6957905907322249\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()  \n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "train_pred = clf.predict(X_train_tfidf)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "print(\"Training Accuracy:\", train_acc)\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6b095",
   "metadata": {},
   "source": [
    "Using a hybrid preprocessing pipeline, TfidfVectorizer with n-grams up to 4, and max_features=3000, we got:\n",
    "Training Accuracy: 78.3%\n",
    "Test Accuracy: 69.6%\n",
    "Overfitting Gap: around 8.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6886da",
   "metadata": {},
   "source": [
    "With optimized preprocessing including general preprocessing, selective POS filtering and n-gram TF-IDF vectorization, the Naive Bayes model reached 78% training and 70% test accuracy. This demonstrates that thoughtful feature engineering, even without complecated models can achieve robust performance and reduce overfitting in multiclass text classification. \n",
    "We notice that this approach achieved a good balance between accuracy, generalization, and computational efficiency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
